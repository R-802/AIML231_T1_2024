{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "437c0427-b81d-4243-99ce-008c84de37df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# AIML 231 Assignment One\n",
    "> Shemaiah Rangitaawa `300601546`\n",
    "\n",
    "## Contents\n",
    "- #### [Classification with SKLearn](#part-one)\n",
    "- #### [Accuracy by Hyperparameter Plots](#task-i)\n",
    "- #### [Summary Tables](#task-ii)\n",
    "- #### [ROC Curve](#task-iii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5239c-e9ab-41dd-8da2-7474b9c73a80",
   "metadata": {},
   "source": [
    "## Install Requirements\n",
    "> I had some issues with the latest version of kaleido, therefore version 0.1.0 must be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0e4dc-b68a-40dc-8567-f687797c4a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training progress monitoring\n",
    "!pip install tqdm\n",
    "\n",
    "# For interactive graphs\n",
    "!pip install plotly\n",
    "\n",
    "# For plotly static image export\n",
    "!conda install python-kaleido==0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30c4dda-b01b-428e-8b5a-872e702d0f13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd48aa-0d4f-4caf-ab7c-4a64b242066d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization library - Plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# To suppress warnings\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "\n",
    "# Progress bar utility\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# NumPy print options\n",
    "np.set_printoptions(precision=3)  # limit precision when printing arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33e9de-dcfb-4983-a2df-43b095e4a97c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768cac1b-e7da-43f4-8f8f-297598eba16d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_files = {\n",
    "    \"ionosphere\": \"data/ionosphere_new.csv\",\n",
    "    \"steelplates\": \"data/steelplates_new.csv\",\n",
    "    \"banknotes\": \"data/banknotes_new.csv\",\n",
    "}\n",
    "datasets  = {}\n",
    "for name, path in csv_files.items():\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        X, y = df.drop(columns=df.columns[-1]), df[df.columns[-1]]\n",
    "        datasets[name] = (X, y)\n",
    "    else:\n",
    "        print(f\"File {path} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847ed603-93e7-4070-8626-1fa65711414a",
   "metadata": {},
   "source": [
    "## Initialize Number of Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccc72e-d4a7-4a24-8cb7-8b067b0bf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrials = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1e420-29b1-4f03-91a7-92b7ff93ccd9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Classification using the SKLearn library <a class=\"anchor\" id=\"part-one\"></a>\n",
    "> Refactored to implement plotly for interactive graphs and tqdm for loading bars.\n",
    "> \n",
    "> Score results are saved to `data/pdframe/NameOfDataset_Classifier_Hyperparameter.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0aa35-8ef7-4181-b655-e7a864cfb83f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def test(dataname, classifier, controlName, controlOptions):\n",
    "    \"\"\"\n",
    "    Test a classifier with various control options on a specified dataset\n",
    "\n",
    "    Parameters:\n",
    "    - dataname: The name of the dataset\n",
    "    - classifier: The classifier class to be tested\n",
    "    - controlName: The name of the hyperparameter to vary\n",
    "    - controlOptions: A list of options/values for the hyperparameter\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with scores for each option and trial\n",
    "    \"\"\"\n",
    "    # Ensure reproducibility\n",
    "    random.seed(100)\n",
    "    np.random.seed(100)\n",
    "\n",
    "    # Initialize path to save results and ensure the directory exists\n",
    "    save_path = f\"data/pdframe/{dataname}_{classifier.__name__}_{controlName}.csv\"\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    \n",
    "    # Load dataset and standardize features\n",
    "    X, y = datasets[dataname]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    scores_list = []  # Store results here\n",
    "    \n",
    "    # Perform trials\n",
    "    for t in tqdm(range(nTrials), desc=f\"{str(dataname).capitalize()}\"):\n",
    "        \n",
    "        # Split dataset into training and testing parts\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)  # 50:50 split\n",
    "        \n",
    "        # Test each hyperparameter option\n",
    "        for option in controlOptions:\n",
    "            \n",
    "            # Initialize classifier with current option\n",
    "            model = classifier(**{controlName: option})\n",
    "            model.fit(X_train, y_train)  # Train modedl\n",
    "            score = model.score(X_test, y_test)  # Evaluate model\n",
    "            scores_list.append({'Option': option, 'Score': score, 'Trial': t})\n",
    "    \n",
    "    # Convert scores list to DataFrame\n",
    "    scores_df = pd.DataFrame(scores_list)\n",
    "    \n",
    "    # Adjust 'Option' column based on controlName specifics\n",
    "    if controlName in ['alpha']:\n",
    "        scores_df['Option'] = np.log10(scores_df['Option'])\n",
    "    elif controlName in ['kernel']:\n",
    "        scores_df['Option'] = scores_df['Option'].astype(str)\n",
    "        \n",
    "    # Save results to CSV\n",
    "    scores_df.to_csv(save_path, index=False)\n",
    "    return scores_df\n",
    "    \n",
    "\n",
    "def test_several_datasets(classifier, controlName, options):\n",
    "    \"\"\"\n",
    "    Test a classifier on several datasets and visualize the results\n",
    "\n",
    "    Parameters:\n",
    "    - classifier: The classifier class to be tested\n",
    "    - controlName: The name of the hyperparameter to vary\n",
    "    - options: A list of options/values for the hyperparameter\n",
    "    \"\"\"\n",
    "    # Prepare subplot figure\n",
    "    fig = make_subplots(rows=1, cols=3, subplot_titles=[\"banknotes\", \"steelplates\", \"ionosphere\"])\n",
    "    datasets_to_test = [\"banknotes\", \"steelplates\", \"ionosphere\"]\n",
    "    \n",
    "    # Test each dataset\n",
    "    for i, dataset in enumerate(datasets_to_test, start=1):\n",
    "        scores_df = test(dataset, classifier, controlName, options)\n",
    "        \n",
    "        # Add a box plot for each option's scores to the subplot\n",
    "        for option in scores_df['Option'].unique():\n",
    "            fig.add_trace(\n",
    "                go.Box(y=scores_df[scores_df['Option'] == option]['Score'], name=str(option), showlegend=False),\n",
    "                row=1, col=i\n",
    "            )\n",
    "            \n",
    "        # Update axes titles\n",
    "        fig.update_xaxes(title=controlName, row=1, col=i)\n",
    "    fig.update_yaxes(title=\"Accuracy\", row=1, col=1)\n",
    "    \n",
    "    # Update layout and display the figure\n",
    "    fig.update_layout(height=500, width=1100, title_text=f\"Performance of {classifier.__name__}\", showlegend=False)\n",
    "    fig.show()\n",
    "    \n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    \n",
    "    # Saving to PDF for vector format\n",
    "    file_name = f\"plots/{classifier.__name__}.pdf\"\n",
    "    fig.write_image(file_name)\n",
    "    print(f\"Figure saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238479d-31d7-449c-bd5d-8f568a230bd1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Plot Generation <a class=\"anchor\" id=\"task-i\"></a>\n",
    "\n",
    "> Results are organized to show the accuracy and hyperparameter settings of the six classifiers, across the three different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5d715-7386-469c-8297-449414087ab0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49a65d-d2d9-4808-bf1f-57839b6bccaa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "test_several_datasets(KNeighborsClassifier,\"n_neighbors\", range(1,6,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafec574-3935-481f-a802-8c95e7b13b93",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a6baa-9107-4ffe-9149-6e3d25b9df1f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "test_several_datasets(LogisticRegression,\"C\", [.1,.5,1.0,2.0, 5.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529e08df-44ac-4cee-9098-76da43733c31",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfdddbf-1df0-44ca-9f77-33dea15db4b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "test_several_datasets(DecisionTreeClassifier,\"max_depth\", range(1,11,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc387e-5bb8-46b4-ac93-9ad9e980a93a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daabe70-fb87-4bc0-8167-8780c9eb8f53",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "test_several_datasets(RandomForestClassifier, \"max_depth\", range(1,11,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669f25ad-09ab-4c54-a9d2-7d324dbb9099",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef874f-af3c-4bd7-bf43-0f31c6c03362",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "test_several_datasets(MLPClassifier, \"alpha\", [1e-5, 1e-3,0.1,10.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f8130-7030-40c0-8ddd-62d9306a81a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Support Vector Classification (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc67785-70cb-426f-b388-650277ccc93f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "test_several_datasets(SVC, \"kernel\" , ['linear','poly', 'rbf', 'sigmoid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2e757-58aa-4439-9bc3-f71b56cafb8f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Summary Tables <a class=\"anchor\" id=\"task-ii\"></a>\n",
    "> `create_summary_tables()` is used to generate dataframes containing the lowest mean test errors and the corresponding hyperparameter values from the CSV files saved in the previous hyperparameter tests, considering different hyperparameters for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490356e-7e89-41bf-9986-224b230c0b55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_summary_tables(datasets, classifier_hyperparams, base_path=\"data/pdframe\"):\n",
    "    \"\"\"\n",
    "    Generate summary tables showing the lowest mean test errors and corresponding \n",
    "    hyperparameters for various classifiers across different datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    - datasets: A list of dataset names to be analyzed\n",
    "    - classifier_hyperparams: A dictionary where keys are classifier names and values are the names of the hyperparameters tested\n",
    "    - base_path: The base path where the CSV files with test scores are stored. Defaults to \"data/pdframe\"\n",
    "    \n",
    "    Returns:\n",
    "    - A tuple of two DataFrames: (lowest_mean_errors, corresponding_hyperparams).\n",
    "      - lowest_mean_errors: DataFrame with classifiers as rows, datasets as columns, and the lowest mean test error as values\n",
    "      - corresponding_hyperparams: DataFrame with classifiers as rows, datasets as columns, and the hyperparameters \n",
    "                                   that led to the lowest mean test error as values\n",
    "    \"\"\"\n",
    "    # Initialize classifiers list and DataFrames for storing summary results\n",
    "    classifiers = list(classifier_hyperparams.keys())\n",
    "    lowest_mean_errors = pd.DataFrame(columns=datasets, index=classifiers)\n",
    "    corresponding_hyperparams = pd.DataFrame(columns=datasets, index=classifiers)\n",
    "\n",
    "    # Iterate over each dataset\n",
    "    for dataset in datasets:\n",
    "        # Iterate over each classifier and its hyperparameter\n",
    "        for classifier, hyperparam in classifier_hyperparams.items():\n",
    "            \n",
    "            # Construct the file path for the CSV file containing test scores\n",
    "            file_path = f\"{base_path}/{dataset}_{classifier}_{hyperparam}.csv\"\n",
    "            \n",
    "            # Check if the file exists; print a message and skip to the next if not\n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"File not found: {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load test scores from the CSV file\n",
    "            scores_df = pd.read_csv(file_path)\n",
    "            # Calculate test error for each test case\n",
    "            scores_df['Test Error'] = 1 - scores_df['Score']\n",
    "            # Calculate mean test error for each hyperparameter option\n",
    "            mean_errors = scores_df.groupby('Option')['Test Error'].mean()\n",
    "            \n",
    "            # Find the hyperparameter option with the lowest mean test error\n",
    "            best_option = mean_errors.idxmin()\n",
    "            lowest_mean_error = mean_errors.min()\n",
    "\n",
    "            # Update the summary tables with the lowest mean error and corresponding hyperparameter for the current classifier and dataset\n",
    "            lowest_mean_errors.at[classifier, dataset] = lowest_mean_error\n",
    "            corresponding_hyperparams.at[classifier, dataset] = best_option\n",
    "\n",
    "    os.makedirs(f\"{base_path}/summary_tables\", exist_ok=True)\n",
    "    \n",
    "    # Save the tables\n",
    "    lowest_mean_errors.to_csv(f\"{base_path}/summary_tables/lowest_mean_errors.csv\", index=True)\n",
    "    corresponding_hyperparams.to_csv(f\"{base_path}/summary_tables/corresponding_hyperparams.csv\", index=True)\n",
    "    \n",
    "    # Return the summary tables\n",
    "    return lowest_mean_errors, corresponding_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012075e7-e919-40f3-9bee-e25e5e08016b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Initialize Hyperparameter Map and Generate Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed951568-7c97-41d4-b7bd-a429c1c3322f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_hyperparams = {\n",
    "    \"DecisionTreeClassifier\": \"max_depth\",\n",
    "    \"KNeighborsClassifier\": \"n_neighbors\",\n",
    "    \"LogisticRegression\": \"C\",\n",
    "    \"MLPClassifier\": \"alpha\",\n",
    "    \"RandomForestClassifier\": \"max_depth\",\n",
    "    \"SVC\": \"kernel\"\n",
    "}\n",
    "\n",
    "lowest_mean_errors_table, corresponding_hyperparams_table = create_summary_tables(\n",
    "    list(datasets.keys()), \n",
    "    classifier_hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3f7db-a18b-422e-8882-f433b8113b29",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Lowest Mean Test Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748e068-0228-4f78-a0c3-d90adffd3018",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lowest_mean_errors_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adfbd1e-55a8-48f2-afe9-8ce8c5b89d96",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter Values for Lowest Mean Test Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c7b15-31be-493a-af38-73649fd5008b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corresponding_hyperparams_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bab249d-f5c2-49e4-8455-a1fa25079724",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# ROC Curve <a class=\"anchor\" id=\"task-iii\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b29106-662d-4c7e-84dc-6c2fd86a310e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "X, y = datasets[\"ionosphere\"]\n",
    "\n",
    "# Standardize the feature values\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_std = scaler.transform(X)\n",
    "\n",
    "# Perform train-test split with a 70:30 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Initialize and train classifier\n",
    "clf = RandomForestClassifier(max_depth=5).fit(X_train, y_train)\n",
    "\n",
    "# Generate and display ROC curve\n",
    "roc_disp = RocCurveDisplay.from_estimator(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a00fc-17ff-4950-816b-c41f88bab3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train classifier\n",
    "clf = SVC(kernel='rbf').fit(X_train, y_train)\n",
    "\n",
    "# Generate and display ROC curve\n",
    "roc_disp = RocCurveDisplay.from_estimator(clf, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
