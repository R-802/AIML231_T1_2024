{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d5868e-c325-46ba-9d9a-23ee37b6f0e0",
   "metadata": {},
   "source": [
    "# AIML231 Assignement One - Part Three\n",
    "> Implementation of the Decision Tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea767c7-906a-4fa6-91ec-60b05dff76fd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b738323-32ed-4e20-ac53-22b844d37578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f15c1-00b7-4264-bbba-57647add24b4",
   "metadata": {},
   "source": [
    "## Node Class Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b9461-e910-49e1-a9e9-e7b267540e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeNode:\n",
    "    def __init__(self, feature=None, value=None, left=None, right=None, is_leaf=False, label=None, depth=0):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.is_leaf = is_leaf\n",
    "        self.label = label\n",
    "        self.depth = depth\n",
    "\n",
    "    \n",
    "    def string_representation(self):\n",
    "        if self.is_leaf:\n",
    "            return ''.join(self.depth*['  '],) + f'leaf:{self.feature}={self.value}&label={self.label}&depth={self.depth}'\n",
    "        else:\n",
    "            return ''.join(self.depth*['  '],) + f'{self.feature}={self.value}&depth={self.depth}\\n->left  ' + self.left.string_representation() + '\\n->right ' + self.right.string_representation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b73af6-8afc-43e8-b214-1f1cd3265934",
   "metadata": {},
   "source": [
    "## Classifier Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0661890-874d-4240-b024-87c534738e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=3, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        # Stop splitting if max depth is reached, if all targets are the same, or if the dataset size is below min_samples_split\n",
    "        if depth == self.max_depth or len(set(y)) == 1 or len(y) < self.min_samples_split: \n",
    "            return DecisionTreeNode(is_leaf=True, label=max(set(y), key=list(y).count), depth=depth)\n",
    "    \n",
    "        best_feature, best_value = self._find_best_split(X, y)\n",
    "        left_idx = X[best_feature] == best_value\n",
    "        right_idx = ~left_idx\n",
    "        \n",
    "        # Further checks to ensure each child node adheres to min_samples_split\n",
    "        if np.sum(left_idx) < self.min_samples_split or np.sum(right_idx) < self.min_samples_split:\n",
    "            return DecisionTreeNode(is_leaf=True, label=max(set(y), key=list(y).count), depth=depth)\n",
    "    \n",
    "        left_child = self._build_tree(X[left_idx], y[left_idx], depth + 1)\n",
    "        right_child = self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
    "    \n",
    "        return DecisionTreeNode(feature=best_feature, value=best_value, left=left_child, right=right_child, depth=depth)\n",
    "    \n",
    "        \n",
    "    def _find_best_split(self, X, y):\n",
    "        best_feature, best_value, best_gain = None, None, 0\n",
    "        for feature in X.columns:\n",
    "            values = list(set(X[feature]))\n",
    "            values.sort()\n",
    "            for value in values:\n",
    "                left_idx = X[feature] == value\n",
    "                right_idx = ~left_idx\n",
    "                gain = self._information_gain(y, y[left_idx], y[right_idx])\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_value = value\n",
    "        return best_feature, best_value\n",
    "\n",
    "    \n",
    "    def _information_gain(self, parent, left, right):\n",
    "        \"\"\"Calculate the information gain of a split.\"\"\"\n",
    "        \n",
    "        def entropy(y):\n",
    "            \"\"\"Calculate the entropy of a label distribution.\"\"\"\n",
    "            # Count occurrences of each label\n",
    "            counts = {}\n",
    "            for label in y:\n",
    "                if label in counts:\n",
    "                    counts[label] += 1\n",
    "                else:\n",
    "                    counts[label] = 1\n",
    "            \n",
    "            # Calculate probabilities\n",
    "            probabilities = [count / len(y) for count in counts.values()]\n",
    "            \n",
    "            # Calculate entropy\n",
    "            return -sum(p * log2(p) for p in probabilities if p > 0)\n",
    "            \n",
    "        parent_entropy = entropy(parent)\n",
    "        left_entropy = entropy(left)\n",
    "        right_entropy = entropy(right)\n",
    "        \n",
    "        # Calculate the weighted average child entropy\n",
    "        child_entropy = (len(left) / len(parent)) * left_entropy + (len(right) / len(parent)) * right_entropy\n",
    "        \n",
    "        # Information gain is the reduction in entropy\n",
    "        return parent_entropy - child_entropy\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        tmp_pred = []\n",
    "        for index, row in X.iterrows():\n",
    "            tmp_pred.append(self._predict_sample(self.root, row))\n",
    "        return tmp_pred\n",
    "\n",
    "    \n",
    "    def _predict_sample(self, node, sample):\n",
    "        \"\"\"Recursively predict the class of a sample based on the decision tree.\"\"\"\n",
    "        if node.is_leaf:\n",
    "            return node.label\n",
    "    \n",
    "        # Traverse the tree based on the split condition\n",
    "        if sample[node.feature] == node.value:\n",
    "            return self._predict_sample(node.left, sample)\n",
    "        else:\n",
    "            return self._predict_sample(node.right, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa28cb4-ace6-47c3-b01c-d9d2cf4146ce",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1832c-059a-41f9-b5a2-2f0a4b27e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code to test the learning of decision trees.\n",
    "data = pd.DataFrame({\n",
    "    'Outlook': ['s', 's', 'o', 'r', 'r', 'r', 'o', 's', 's', 'r', 's', 'o', 'o', 'r'],\n",
    "    'Humidity': ['h', 'h', 'h', 'h', 'n', 'n', 'n', 'h', 'n', 'n', 'n', 'h', 'n', 'h'],\n",
    "    'Wind': ['w', 's', 'w', 'w', 'w', 's', 's', 'w', 'w', 'w', 's', 's', 'w', 's'],\n",
    "    'PlayTennis': [1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
    "})\n",
    "\n",
    "# Train the decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(data[['Outlook', 'Humidity', 'Wind']], data['PlayTennis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1afaf1b-e085-4e66-8ad0-ff47de31b692",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc8a21-308f-409f-86aa-b27275d6646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = clf.predict(\n",
    "    pd.DataFrame({\n",
    "        'Outlook': ['o', 's', 'r', 'o'],\n",
    "        'Humidity': ['n', 'h', 'h', 'n'],\n",
    "        'Wind': ['w', 's', 's', 'w']\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b115fa-9a34-4e4f-9a50-511db244d0dd",
   "metadata": {},
   "source": [
    "## Tree Representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8c6b1-dabb-4343-9bec-bd3595d8dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.root.string_representation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32170841-28f2-472b-8e66-fe96dd982d60",
   "metadata": {},
   "source": [
    "## Graphical Tree Representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e748c344-3ed6-43dc-b108-3a1fe2dd79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plot_tree import plot_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b8371-7597-456c-b468-4d3071533e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_tree(clf.root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
