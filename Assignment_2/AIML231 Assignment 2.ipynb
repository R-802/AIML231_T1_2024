{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a8d0f4-bc52-49c9-a4c0-1ee2930bc265",
   "metadata": {},
   "source": [
    "# AIML231 Assignment 2\n",
    "\n",
    "> Shemaiah Rangitaawa `300601546`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b4de5-414b-498d-a5c7-f71e88bf33c7",
   "metadata": {},
   "source": [
    "# Part Two | Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10be5bb-6061-4de3-b2af-3138a9329d8f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9791d1-7f7e-4406-a4a7-ac992e411685",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import r_regression\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba71a6-0614-49e1-80bc-e847ace6f381",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01eac1-41e3-4268-a1ba-0bfb47c770ba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load full data and split the dataset into feature matrix X and label vector y\n",
    "df = pd.read_csv('./Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6ddfd-6274-4e42-8e17-50892383f433",
   "metadata": {},
   "source": [
    "## Summary Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6b9bc7-8328-409c-b2ef-91d2746824be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(df):\n",
    "    # Number of instances and features\n",
    "    num_instances = df.shape[0]\n",
    "    num_features = df.shape[1] - 1  # excluding the target variable Class\n",
    "    print(f\"Total number of instances: {num_instances}\")\n",
    "    print(f\"Number of features (excluding Class): {num_features}\")\n",
    "    \n",
    "    # Distinguishing between categorical and numerical features\n",
    "    categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    print(f\"Number of categorical features: {len(categorical_features)}\")\n",
    "    print(f\"Number of numerical features: {len(numerical_features)}\")\n",
    "\n",
    "stats(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6547e9-bc64-4146-bd3a-c14fccafd52d",
   "metadata": {},
   "source": [
    "## Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6309d-7130-4883-9217-001a73e614d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical columns for correlation calculation\n",
    "numerical_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Calculate the Pearson correlation matrix for numerical data only\n",
    "correlation_matrix = numerical_df.corr()\n",
    "target_correlation = correlation_matrix['Class'].drop('Class')  # Exclude self-correlation\n",
    "\n",
    "# Sort the correlations to find the top three with the highest absolute values\n",
    "top_three_correlations = target_correlation.abs().sort_values(ascending=False).head(3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Top three numerical features with the highest correlation with 'Credit Risk':\")\n",
    "top_three_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0eafc1-7a01-4c71-ba86-eb311a34e75b",
   "metadata": {},
   "source": [
    "## Histograms of the Top Three Highest Correlating Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4927cce1-8f24-4a1e-801a-8de7d896e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Features with descriptions\n",
    "features = ['Att2 (Duration in month)', 'Att5 (Credit amount)', 'Att13 (Age in years)', 'Class (Credit Risk)']\n",
    "\n",
    "# Create a 2x2 subplot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))  # Adjust the size as needed\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes\n",
    "\n",
    "# Colors for each plot\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    # Use Attribute number for X axis label\n",
    "    short_label = feature.split(' ')[0]\n",
    "    \n",
    "    sns.histplot(df[short_label], kde=True, bins='fd', color=colors[i], ax=axes[i])\n",
    "    axes[i].set_title(f'Histogram of {feature}')\n",
    "    axes[i].set_xlabel(short_label)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Calculate and display skewness and kurtosis\n",
    "    feature_skewness = skew(df[short_label].dropna())  # Drop null values for calculation\n",
    "    feature_kurtosis = kurtosis(df[short_label].dropna())\n",
    "    print(f\"{short_label} - Skewness: {feature_skewness:.2f}, Kurtosis: {feature_kurtosis:.2f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0e0bf-0282-456d-b054-40b9f4ca244b",
   "metadata": {},
   "source": [
    "## Checking for Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674ef26-1cdf-476a-a40c-7aa380e0b127",
   "metadata": {},
   "source": [
    "> The Att1 feature has 65 null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf62b0-5dea-4db3-a55a-fc170b22a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_null_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    total_cells = np.prod(df.shape)\n",
    "    total_missing = missing_values.sum()\n",
    "    \n",
    "    print(\"Missing values in each feature:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "    print(f\"\\nTotal missing values: {total_missing}\")\n",
    "    print(f\"Percentage of dataset missing: {total_missing / total_cells * 100:.2f}%\")\n",
    "\n",
    "find_null_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0a72c-bbf9-442c-a320-d85df81abf0d",
   "metadata": {},
   "source": [
    "# Part Three | Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d232942-d44b-4ee3-9d0f-c36baa9fe339",
   "metadata": {},
   "source": [
    "## 80:20 Train and Test Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b2572-b30f-4ad9-8156-b281120ba3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df.drop('Class', axis=1),  df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b72c0-569a-4ba3-80cb-a335994a31ce",
   "metadata": {},
   "source": [
    "## Pipeline Import and Preprocessing\n",
    "The `preprocess` function prepares training and testing datasets applying several preprocessing steps to pandas DataFrame. It performs the following tasks:\n",
    "\n",
    "1. **Converts categorical data to numeric**: It imputes missing values in ordinal columns, encodes ordinal and non-ordinal categorical attributes, and handles potential multicollinearity in one-hot encoding by dropping the first category.\n",
    "2. **Handles missing values in numeric columns** by using median imputation.\n",
    "3. **Standardizes numeric data** to have zero mean and unit variance.\n",
    "\n",
    "The function outputs the transformed data as new pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8190f-48ff-43a2-b08f-327bf4cd2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline import preprocess\n",
    "\n",
    "# Process data\n",
    "X_train_processed, X_test_processed = preprocess(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795683c5-8673-42f0-95c3-c6c06bd0d21d",
   "metadata": {},
   "source": [
    "### Processed Data Infomation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdadfd75-0813-41fa-a13d-59bd40e553e1",
   "metadata": {},
   "source": [
    "> Mean imputation performed in preprocessing fills in the null entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d7f177-ee3d-4cf5-81f0-bb4704ce27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_null_values(X_train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a6a77-c5cd-4b70-8bb3-dd110c1f1813",
   "metadata": {},
   "source": [
    "> Preprocessing makes all features numeric, ordinal encoding adds 16 new features, 4 for each of the four ordinal attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d57be-1dde-4d2e-aab4-622fbf336563",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(X_train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be5eca2-1fa3-42f8-b289-c74cbbbae188",
   "metadata": {},
   "source": [
    "> The preprocessing function was also designed to retain feature names for simple analysis in subsequent sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adceae53-7691-419f-88ce-d543958b2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310474ba-7e38-4b39-94de-ae93c6af2dde",
   "metadata": {},
   "source": [
    "# Part Four | Feature Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58a93f-3a41-46d0-8759-274cb5866e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frame to numpy array\n",
    "X_train_nparr, X_test_nparr = X_train_processed.values, X_test_processed.values\n",
    "y_train_nparr, y_test_nparr = y_train.values, y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603c907-cc5f-433e-aa5f-1a8c1e7b23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attributes import attribute_dict\n",
    "\n",
    "def get_feature_description(code):\n",
    "    \"\"\"\n",
    "    Retrieves a feature's description based on its code, which could include an attribute key and optionally a value key after an underscore.\n",
    "    :params code (str): The feature code.\n",
    "    :returns (str): Description/name of the feature, or \"Unknown Attribute\"/\"Unknown Value\" if keys are not recognized.\n",
    "    \"\"\"\n",
    "    parts = code.split('_')\n",
    "    att_key = parts[0]\n",
    "    value_key = parts[1] if len(parts) > 1 else None\n",
    "    \n",
    "    if att_key in attribute_dict:\n",
    "        if value_key and 'Values' in attribute_dict[att_key]:\n",
    "            return f\"{attribute_dict[att_key]['Description']} - {attribute_dict[att_key]['Values'].get(value_key, 'Unknown Value')}\"\n",
    "        return attribute_dict[att_key]['Description']\n",
    "    return \"Unknown Attribute\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fbb00b-9b37-4f69-bcd3-8e17e24fc852",
   "metadata": {},
   "source": [
    "### Top n Features After Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1ca33-6859-4e64-8d6e-26528cc58f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline import feature_ranking\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import Helper\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Obtain the indices of the top n features from the ranking function\n",
    "top_features_indices = feature_ranking(X_train_nparr, y_train_nparr, no_features=5)\n",
    "\n",
    "# Get the feature names corresponding to the top indices\n",
    "top_feature_codes = X_train_processed.columns[top_features_indices].tolist()\n",
    "\n",
    "# Display the rank and feature name using a function to get the feature's description\n",
    "print(\"Feature Ranking with MI:\")\n",
    "for index, feature_name in zip(top_features_indices, top_feature_codes):\n",
    "    print(f\"    {index} : {get_feature_description(feature_name)}\")\n",
    "\n",
    "# Evaluate the model using all features\n",
    "all_features_accuracy = Helper.evaluation(clf, X_train_nparr, y_train_nparr, X_test_nparr, y_test_nparr)\n",
    "print(f\"\\nAccuracy of using all features: {all_features_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the model using only the top five features\n",
    "top_features_accuracy = Helper.evaluation(\n",
    "    clf,\n",
    "    X_train_nparr[:, top_features_indices],\n",
    "    y_train_nparr,\n",
    "    X_test_nparr[:, top_features_indices],\n",
    "    y_test_nparr\n",
    ")\n",
    "print(f\"Accuracy of using top five features: {top_features_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524cb63b-5f83-43de-aa60-4f97c3a6e287",
   "metadata": {},
   "source": [
    "## Pearson Correlation Heatmap for Features Ranked with MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698357e2-604f-40d8-be58-b7e71d24a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with just the top features\n",
    "top_features_descriptions_mi = [get_feature_description(name) for name in top_feature_codes]\n",
    "X_top_features = pd.DataFrame(X_train_nparr[:, top_features_indices], columns=top_features_descriptions_mi)\n",
    "\n",
    "# Compute the Pearson correlation matrix\n",
    "correlation_matrix = X_top_features.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', linewidths=.5)\n",
    "plt.title('Heatmap of Pearson Correlation Between Top 5 Features Selected with MI')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b8a81-25d5-4c9c-b52f-e063f38ba944",
   "metadata": {},
   "source": [
    "# Part Five | Sequential Forward Feature Selection (SFFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752eda27-cad3-4833-875d-2b61f9d6b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline import sequential_feature_selection\n",
    "\n",
    "# Perform feature selection\n",
    "sffs_top_features = sequential_feature_selection(X_train_nparr, y_train_nparr, no_features=5)\n",
    "sffs_feature_codes = X_train_processed.columns[sffs_top_features].tolist()\n",
    "\n",
    "# Print the index and feature name with descriptions\n",
    "print(\"Feature Ranking with SFFS:\")\n",
    "for index, code in zip(sffs_top_features, sffs_feature_codes):\n",
    "    print(f\"     {index} : {get_feature_description(code)}\")\n",
    "\n",
    "# Print accuracy using all features\n",
    "print(f\"\\nAccuracy of using all features: {all_features_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the model using the top five features selected by SFFS\n",
    "top_features_accuracy = Helper.evaluation(\n",
    "    clf,\n",
    "    X_train_nparr[:, sffs_top_features],\n",
    "    y_train_nparr,\n",
    "    X_test_nparr[:, sffs_top_features],\n",
    "    y_test_nparr\n",
    ")\n",
    "print(f\"Accuracy of using top five features: {top_features_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff560bc9-fde7-4827-bd3f-33a044736f88",
   "metadata": {},
   "source": [
    "## Pearson Correlation Heatmap for Features Ranked with SFFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbac23-d61a-4845-8985-91cf7ec4df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with just the top features\n",
    "top_features_descriptions_sffs = [get_feature_description(name) for name in sffs_feature_codes]\n",
    "X_top_features = pd.DataFrame(X_train_nparr[:, sffs_top_features], columns=top_features_descriptions_sffs)\n",
    "\n",
    "# Compute the Pearson correlation matrix\n",
    "correlation_matrix = X_top_features.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', linewidths=.5)\n",
    "plt.title('Heatmap of Pearson Correlation Between Top 5 Features Ranked With SFFS')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
